behaviors:
    DungeonMaster:
        trainer_type: ppo
        hyperparameters:
            batch_size: 1024
            buffer_size: 10240
            learning_rate: 0.0003
            beta: 0.005
            epsilon: 0.2
            lambd: 0.95
            num_epoch: 3
            learning_rate_schedule: linear
            beta_schedule: linear
            epsilon_schedule: linear
        network_settings:
            normalize: False
            hidden_units: 128
            num_layers: 2
            vis_encode_type: simple
            memory: None
            goal_conditioning_type: hyper
            deterministic: False
        reward_signals:
            extrinsic:
            gamma: 0.99
            strength: 1.0
            network_settings:
               normalize: False
               hidden_units: 128
               num_layers: 2
               vis_encode_type: simple
               memory: None
               goal_conditioning_type: hyper
               deterministic: False
        init_path: None
        keep_checkpoints: 5
        checkpoint_interval: 500000
        max_steps: 500000
        time_horizon: 64
        summary_freq: 50000
        threaded: False
        self_play:
            window: 10
            play_against_latest_model_ratio: 0.5
            save_steps: 50000
            swap_steps: 2000
            team_change: 100000
        behavioral_cloning: None